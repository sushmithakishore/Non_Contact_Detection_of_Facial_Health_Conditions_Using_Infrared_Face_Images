# üå°Ô∏è Non-Contact Detection of Facial Health Conditions Using Infrared Images

## üìå Overview

This project develops a computer vision‚Äìbased framework for non-contact detection of facial health conditions using infrared (thermal) face images. The objective is to analyze temperature distribution patterns and spatial facial features to enable automated, non-invasive condition classification.

The system implements a complete deep learning pipeline including image preprocessing, feature extraction, model training, and performance evaluation.

---

## üß™ Methodology

### 1Ô∏è‚É£ Image Preprocessing
- Infrared image normalization and noise reduction  
- Face detection and region-of-interest (ROI) extraction  
- Image resizing and pixel scaling  
- Data augmentation for model generalization  

### 2Ô∏è‚É£ Feature Engineering
- Extraction of thermal distribution patterns  
- Spatial feature mapping from facial regions  
- Conversion of images into model-compatible tensor representations  

### 3Ô∏è‚É£ Model Development
- Implementation of CNN-based deep learning architectures  
- Hyperparameter tuning for optimal convergence  
- Regularization techniques to mitigate overfitting  
- Train-validation splitting for performance assessment  

### 4Ô∏è‚É£ Model Evaluation
- Accuracy, Precision, Recall, F1-Score  
- Confusion Matrix analysis  
- ROC-AUC evaluation  
- Comparative validation across model variants  

---

## üõ†Ô∏è Tech Stack

- **Programming:** Python  
- **Image Processing:** OpenCV  
- **Data Handling:** NumPy, Pandas  
- **Modeling:** TensorFlow / PyTorch, Scikit-learn  
- **Visualization:** Matplotlib  

---

## üéØ Objective

To design a reliable, non-invasive health monitoring system capable of detecting condition-specific patterns from infrared facial imagery using deep learning methodologies.
